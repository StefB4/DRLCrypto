{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5045b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os \n",
    "\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "# TODO\n",
    "\n",
    "# prices nicht skewen? \n",
    "# non negative balance wie an agent feedbacken? \n",
    "# wie sicherstellen, dass nur innerhalb des balance gekauft wird? \n",
    "# starten immer mit random timestep oder von anfang an \n",
    "# turbulence mit angepasster reward function \n",
    "# cut action von [-1,1]? necessary? \n",
    "# flatten observation? sonst lÃ¤uft stable baseline nicht \n",
    "\n",
    "PROCESSEDDATA = \"./../processeddata\"\n",
    "#PROCESSEDDATA = os.path.dirname(os.path.abspath(__file__)) + \"/../processeddata\"\n",
    "\n",
    "INITIAL_BALANCE = 2000\n",
    "# for normalization\n",
    "MAX_BALANCE = 1000000 \n",
    "MAX_PRICE = 10000 \n",
    "MAX_INDEX_VAL = 1000 \n",
    "MAX_HOLDING_VAL = 10000  \n",
    "MAX_BUYING_AMOUNT = 10000 \n",
    "TRANSACTION_PERCENTAGE_COST = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77a5697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CryptoEnv(gym.Env):\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"hello from CryptoEnv\")\n",
    "    \n",
    "        super(CryptoEnv, self).__init__()\n",
    "        \n",
    "        self.crypto_data = [] # ['unixtime', 'interpolateddata', 'open', 'close', 'low', 'high', 'macd', 'rsi', 'cci', 'adx']\n",
    "        self.crypto_data_names = [] # ['ADA', 'ETH', 'XRP', 'XMR', 'LTC']\n",
    "        self._read_processed_data()\n",
    "        \n",
    "        # TODO \n",
    "        self.action_space = spaces.Box(low=-1,high=+1,shape=(len(self.crypto_data_names),), dtype=np.float32)\n",
    "        # for each crypto (normalized from -1 to +1): negative: sell, 0: hold, positive: buy \n",
    "        #self.action_space = spaces.Box(low=0.1,high=+0.9998,shape=(len(self.crypto_data_names),), dtype=np.float32)\n",
    "        \n",
    "        # TODO \n",
    "        obs_lows = [0] + [0] * len(self.crypto_data_names) * 2 + [-1] * len(self.crypto_data_names) + [0] * len(self.crypto_data_names) * 2 + [-1] * len(self.crypto_data_names)\n",
    "        obs_highs =[1] + [1] * len(self.crypto_data_names) * 6 \n",
    "        self.observation_space = spaces.Box(low = np.array(obs_lows), high = np.array(obs_highs), dtype=np.float32)\n",
    "        #self.observation_space = spaces.Box(low=0.1, high=0.9988, shape=((len(self.crypto_data_names) * 6 + 1),), dtype=np.float32)\n",
    "       \n",
    "        # all normalized from -1 to 1                                     \n",
    "        # balance (pure money) (>= 0, single number)\n",
    "        # amount owned of each crypto (>= 0, vector)\n",
    "        # close price of each crypto (>= 0, vector)\n",
    "        # MACD of each crypto (neg or pos, vector)\n",
    "        # RSI of each crypto (>= 0, vector)\n",
    "        # CCI of each crypto (>= 0, vector)\n",
    "        # ADX of each crypto (neg or pos, vector)\n",
    "        \n",
    "        \n",
    "        # init used variables, are reset in reset()\n",
    "        self.current_step = -1\n",
    "        self.current_balance = -2\n",
    "        self.current_holdings = np.ones((len(self.crypto_data_names),)) # np.ones((len(self.crypto_data_names),)) * -1\n",
    "        \n",
    "        # TODO \n",
    "        # set in _observe_step()\n",
    "        self.current_observation = np.array([np.array([1]),np.array([[0.8,0.8,0.8,0.8,0.8],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])]) #self.current_observation = -1 \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def _read_processed_data(self):\n",
    "        for crypto_file in glob.glob(PROCESSEDDATA + \"/*.csv\"):\n",
    "            self.crypto_data.append(pd.read_csv(os.path.join(crypto_file), index_col=0))\n",
    "            name = os.path.basename(crypto_file)\n",
    "            name = name.split(\"BTC\")[0]\n",
    "            self.crypto_data_names.append(name)\n",
    "        \n",
    "        # drop some unimportant stuff \n",
    "        for idx, _ in enumerate(self.crypto_data):\n",
    "            self.crypto_data[idx].drop(columns=[\"timestamp\",\"openbtc\",\"lowbtc\",\"highbtc\",\"closebtc\"], inplace = True)\n",
    "            self.crypto_data[idx].drop(columns=[\"high\",\"low\",\"open\",\"interpolateddata\"], inplace = True)\n",
    "    \n",
    "    \n",
    "    def _perform_action(self,action):\n",
    "        \n",
    "        # TODO\n",
    "        #return\n",
    "        \n",
    "        # Implementation:\n",
    "        # Sell individual holdings where possible \n",
    "        # Only buy all that are planned to be bought or none  \n",
    "        \n",
    "        \n",
    "        # De-normalize \n",
    "        action = action * MAX_BUYING_AMOUNT \n",
    "        \n",
    "        # total buy price\n",
    "        total_buy_price = 0\n",
    "        \n",
    "        \n",
    "        # performs sells if possible immediately, count all buys together to evaluate if possible \n",
    "        for idx, amount in enumerate(action):\n",
    "            \n",
    "            \n",
    "            \n",
    "            # want to sell\n",
    "            if (amount < 0): \n",
    "                abs_amnt = np.abs(amount)\n",
    "                if (self.current_holdings[idx] < abs_amnt):  # less crypto available in holdings than wanted to sell \n",
    "                    pass # do not sell and keep balance\n",
    "                else: # crypto available\n",
    "                    self.current_holdings[idx] -= abs_amnt # sell, remove from holdings\n",
    "                    self.current_balance += (abs_amnt * self.current_observation[1][1][idx] * MAX_PRICE) * (1 - TRANSACTION_PERCENTAGE_COST / 100) # add money to balance, deduct transaction cost; get price from observation\n",
    "            \n",
    "            # in case of hold do nothing \n",
    "            \n",
    "            # want to buy \n",
    "            elif (amount > 0):\n",
    "                total_buy_price += amount * self.current_observation[1][1][idx] * MAX_PRICE # add price of wanted cryptos to total buy price \n",
    "        \n",
    "        \n",
    "        # when buys are possible, perform\n",
    "        if total_buy_price <= self.current_balance:\n",
    "            \n",
    "            for idx, amount in enumerate(action):\n",
    "                \n",
    "                if (amount > 0):\n",
    "                    self.current_holdings[idx] += amount # buy, add to holdings\n",
    "                    self.current_balance -= (amount * self.current_observation[1][1][idx] * MAX_PRICE) * (1 + TRANSACTION_PERCENTAGE_COST / 100) # remove money from balance, deduct transaction cost; get price from observation\n",
    "                    if self.current_balance < 0:\n",
    "                        self.current_balance = 0 # in case transaction cost was too expensive, clip to 0 \n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "    def _calc_portfolio_value(self):\n",
    "        \n",
    "        # TODO \n",
    "        #return 1 \n",
    "        \n",
    "        #print(self.current_balance + np.squeeze(np.dot(self.current_holdings,np.squeeze(self.current_observation[1][1] * MAX_PRICE))))\n",
    "        return self.current_balance + np.squeeze(np.dot(self.current_holdings,np.squeeze(self.current_observation[1][1] * MAX_PRICE)))\n",
    "        \n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        # TODO \n",
    "        #return self._observe_step(), 20, 0, {}\n",
    "        \n",
    "        # Log\n",
    "        if (self.current_step % 100 == 0 and False):\n",
    "            clear_output(wait=True)\n",
    "            print(\"Timestep: \" + str(self.current_step) + \" Datetime: \" + str(pd.to_datetime(self.crypto_data[0].loc[self.current_step]['unixtime'],unit='s')))\n",
    "            print(\"Current balance: \" + str(self.current_balance))\n",
    "            for idx, holding in enumerate(self.current_holdings):\n",
    "                print(self.crypto_data_names[idx] + \" holding: \" + str(holding) + \"\\t\" + self.crypto_data_names[idx] + \" price: \" + str(self.current_observation[1][1][idx] * MAX_PRICE) + \" normalized price: \" + str(self.current_observation[1][1][idx]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        portfolio_val_before = self._calc_portfolio_value()\n",
    "        \n",
    "        # TODO\n",
    "        #obs = self._observe_step()\n",
    "        \n",
    "        # Execute one time step within the environment\n",
    "        self._perform_action(action)\n",
    "        \n",
    "        portfolio_val_after = self._calc_portfolio_value()\n",
    "\n",
    "        self.current_step += 1\n",
    "\n",
    "        done = False \n",
    "        \n",
    "        # Reached end of data\n",
    "        if self.current_step >= len(self.crypto_data[0]['close']): \n",
    "            print(\"Reached end of data\")\n",
    "            done = True\n",
    "            \n",
    "\n",
    "        reward = portfolio_val_after - portfolio_val_before # transaction costs are already included in the portfolio \n",
    "        \n",
    "        # Episode done if balance below 0 \n",
    "        if self.current_balance < 0:\n",
    "            print(\"Balance below 0\")\n",
    "            done = True \n",
    "        \n",
    "\n",
    "        obs = self._observe_step()\n",
    "        \n",
    "\n",
    "        return obs, reward, done, {}\n",
    "        \n",
    "    \n",
    "    \n",
    "    # all uncommented here commented -> remove comment, error occurs\n",
    "    # when perform action is uncommented -> almost none so it's probably the combination of these two\n",
    "    def _observe_step(self):\n",
    "        \n",
    "        # TODO\n",
    "        #return np.ones((31,)) * 0.5\n",
    "        \n",
    "        crypto_info_frames = []\n",
    "        \n",
    "        # extract relevant data for all cryptos \n",
    "        for idx, _ in enumerate(self.crypto_data):            \n",
    "            crypto_info_frames.append(self.crypto_data[idx].iloc[self.current_step])\n",
    "        crypto_info_df = pd.concat(crypto_info_frames, axis=1)\n",
    "        crypto_info_df = crypto_info_df.T\n",
    "        crypto_info_np = crypto_info_df.to_numpy()\n",
    "        crypto_info_np = np.array(crypto_info_np[:,1:])\n",
    "        # column 0: close, 1: macd, 2: rsi, 3: cci, 4: adx \n",
    "        # \n",
    "        # debugging\n",
    "        #print(\"crypto_info_df:\")\n",
    "        #print(crypto_info_df)\n",
    "        #print(\"crypto_info_np (removed unix time) (column 0: close, 1: macd, 2: rsi, 3: cci, 4: adx):\")\n",
    "        #print(crypto_info_np)\n",
    "        \n",
    "        \n",
    "        # normalize \n",
    "        crypto_info_np[:,0] = crypto_info_np[:,0] / MAX_PRICE\n",
    "        crypto_info_np[:,1] = crypto_info_np[:,1] / MAX_INDEX_VAL\n",
    "        crypto_info_np[:,2] = crypto_info_np[:,2] / MAX_INDEX_VAL\n",
    "        crypto_info_np[:,3] = crypto_info_np[:,3] / MAX_INDEX_VAL\n",
    "        crypto_info_np[:,4] = crypto_info_np[:,4] / MAX_INDEX_VAL\n",
    "        # debugging\n",
    "        #print(\"crypto_info_np (normalized):\")\n",
    "        #print(crypto_info_np)\n",
    "        \n",
    "        # concat balance and prices and indices \n",
    "        observation = np.vstack([self.current_holdings / MAX_HOLDING_VAL,crypto_info_np.T])\n",
    "        observation = np.array([[self.current_balance / MAX_BALANCE], observation], dtype=object)\n",
    "        # observation make up \n",
    "        # [current balance]\n",
    "        # [ [current holdings 1, 2, 3, ...]\n",
    "        #   [ close 1, 2, 3, ... ] \n",
    "        #   [ macd 1, 2, 3, ... ]  \n",
    "        #   [ rsi 1, 2, 3, ... ] \n",
    "        #   [ cci 1, 2, 3, ... ] \n",
    "        #   [ adx 1, 2, 3, ... ] \n",
    "        # ]\n",
    "        #\n",
    "        # debugging\n",
    "        #print(\"Current balance: \" + str(self.current_balance) + \" Current balance normalized: \" + str(self.current_balance / MAX_BALANCE))\n",
    "        #print(\"Current holdings: \\n\" + str(self.current_holdings) + \"\\n Current holdings normalized: \\n\" + str(self.current_holdings / MAX_HOLDING_VAL))\n",
    "        #print(\"Full observation shape: \" + str(np.shape(observation)))\n",
    "        #print(\"Observation index 0 shape: \" + str(np.shape(observation[0])))\n",
    "        #print(\"Observation index 0 content:\")\n",
    "        #print(observation[0])\n",
    "        #print(\"Observation index 1 shape: \" + str(np.shape(observation[1])))\n",
    "        #print(\"Observation index 1 content: (row 0: current holding, 1: close, 2: macd, 3: rsi, 4: cci, 5: adx)\")\n",
    "        #print(observation[1])\n",
    "        \n",
    "        \n",
    "        self.current_observation = observation \n",
    "        \n",
    "        # make observation into single vector for return \n",
    "        return np.insert(observation[1].flatten(), 0, observation[0], axis=0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def reset(self):\n",
    "        \n",
    "        # Reset to a random number from start until half of available data points \n",
    "        self.current_step = random.randint(\n",
    "            0, len(self.crypto_data[0]['close']) // 2)\n",
    "        \n",
    "        self.current_balance = INITIAL_BALANCE\n",
    "        self.current_holdings = np.zeros((len(self.crypto_data_names)),) # start with no cryptos \n",
    "        # current prices, macd, rsi, cci, adx are obtained from the data \n",
    "        \n",
    "        # Observe with the newly set values \n",
    "        observation = self._observe_step()\n",
    "        \n",
    "        return observation \n",
    "\n",
    "    \n",
    "    def render(self, mode='human', close=False):\n",
    "               \n",
    "        # Render the environment to the screen\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "058d3a9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello from CryptoEnv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-6c62823a3c17>:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  self.current_observation = np.array([np.array([1]),np.array([[0.8,0.8,0.8,0.8,0.8],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])]) #self.current_observation = -1\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "The observation returned by the `reset()` method does not match the given observation space",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9b94ddb37aeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0menv_vanilla\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCryptoEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcheck_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_vanilla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/ReAlly/lib/python3.8/site-packages/stable_baselines3/common/env_checker.py\u001b[0m in \u001b[0;36mcheck_env\u001b[0;34m(env, warn, skip_render_check)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;31m# ============ Check the returned values ===============\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0m_check_returned_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;31m# ==== Check the render method and the declared render modes ====\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ReAlly/lib/python3.8/site-packages/stable_baselines3/common/env_checker.py\u001b[0m in \u001b[0;36m_check_returned_values\u001b[0;34m(env, observation_space, action_space)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0m_check_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"reset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;31m# Sample a random action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ReAlly/lib/python3.8/site-packages/stable_baselines3/common/env_checker.py\u001b[0m in \u001b[0;36m_check_obs\u001b[0;34m(obs, observation_space, method_name)\u001b[0m\n\u001b[1;32m    100\u001b[0m         )\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     assert observation_space.contains(\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     ), \"The observation returned by the `{}()` method does not match the given observation space\".format(method_name)\n",
      "\u001b[0;31mAssertionError\u001b[0m: The observation returned by the `reset()` method does not match the given observation space"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "env_vanilla = CryptoEnv()\n",
    "check_env(env_vanilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62f79a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello from CryptoEnv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-6c62823a3c17>:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  self.current_observation = np.array([np.array([1]),np.array([[0.8,0.8,0.8,0.8,0.8],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1],[1,1,1,1,1]])]) #self.current_observation = -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 453  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 4    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 437         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003576217 |\n",
      "|    clip_fraction        | 0.0154      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.11       |\n",
      "|    explained_variance   | -3.16       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0265     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.000371    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 432          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039239004 |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.11        |\n",
      "|    explained_variance   | -0.938       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0118      |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00618     |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 3.75e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 412         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008081432 |\n",
      "|    clip_fraction        | 0.0637      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.08       |\n",
      "|    explained_variance   | 0.13        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00753    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00924    |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 3.42e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 409          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070494018 |\n",
      "|    clip_fraction        | 0.0529       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.06        |\n",
      "|    explained_variance   | -0.747       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0139      |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00832     |\n",
      "|    std                  | 0.991        |\n",
      "|    value_loss           | 1.36e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 407         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011168857 |\n",
      "|    clip_fraction        | 0.0623      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.06       |\n",
      "|    explained_variance   | -0.286      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0285     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00852    |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 1.7e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008432317 |\n",
      "|    clip_fraction        | 0.0534      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.08       |\n",
      "|    explained_variance   | 0.0478      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0101      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00637    |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 1.24e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 404         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006224295 |\n",
      "|    clip_fraction        | 0.0729      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.08       |\n",
      "|    explained_variance   | -0.0983     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00382     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 1.58e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 403        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 45         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01322631 |\n",
      "|    clip_fraction        | 0.1        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.08      |\n",
      "|    explained_variance   | -0.0621    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0319    |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0113    |\n",
      "|    std                  | 0.998      |\n",
      "|    value_loss           | 2.19e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011079197 |\n",
      "|    clip_fraction        | 0.0603      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.06       |\n",
      "|    explained_variance   | -0.238      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000181    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00823    |\n",
      "|    std                  | 0.991       |\n",
      "|    value_loss           | 1.31e-05    |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "\n",
    "\n",
    "# The algorithms require a vectorized environment to run\n",
    "env = DummyVecEnv([lambda: CryptoEnv()])\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1) # MlpPolicy\n",
    "model.learn(total_timesteps=20000)\n",
    "\n",
    "obs = env.reset()\n",
    "for i in range(1000):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    if done:\n",
    "        obs = env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd647860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2310a291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
